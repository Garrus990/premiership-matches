{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1b437-eb76-4bf9-9d36-25fc95723094",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f127d-e5dd-499f-87f5-d96fa665d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as pln\n",
    "import scipy\n",
    "import statsmodels\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Categorical, Integer, Real\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a3d57-a54e-4dd6-baa5-3b7cf336cff1",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c98c48-0d18-406e-9a5c-2b2d031be85a",
   "metadata": {},
   "source": [
    "The data comes from [kaggle](https://www.kaggle.com/datasets/pablohfreitas/all-premier-league-matches-20102021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90767b-440d-4a17-b29f-f13b89f8abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  not sure if that will be necessary, but just in case\n",
    "features_dictionary = (\n",
    "    pd.read_csv(\n",
    "        \"../data/input/data_dictionary.txt\", sep=\":\", skipinitialspace=True, header=None\n",
    "    )\n",
    "    .applymap(lambda x: x.strip())\n",
    "    .set_index(0)\n",
    "    .to_dict()[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d01b4d-b184-42cd-9281-013ce03cb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "premiership_data = (\n",
    "    pd.read_csv(\n",
    "        \"../data/input/df_full_premierleague.csv\", index_col=0, parse_dates=[\"date\"]\n",
    "    )\n",
    "    .drop(columns=[\"link_match\"])  # unnecessary\n",
    "    .sort_values([\"season\", \"date\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd763d3-bb5e-4cce-bd48-c9ae3b35759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "premiership_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc120b0-8a63-42a3-b7bd-d53ca1aa72c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "premiership_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01835c-0334-4ee3-a2ef-ad575e675f65",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca9e82-6167-4a4f-b3bc-f810d4d4e1d0",
   "metadata": {},
   "source": [
    "Since we are looking for predictions for **future** matches, we need to stick only to variables that relate to the past performances of a given team. Hence, we will not be using features that apply to the current match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1f574-4972-4402-a120-89b282aab5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fields = [\n",
    "    k for k, v in features_dictionary.items() if \"accumulated until the last match\" in v\n",
    "]\n",
    "technical_fields = [\n",
    "    \"season\",\n",
    "    \"date\",\n",
    "    \"home_team\",\n",
    "    \"away_team\",\n",
    "    \"result_full\",\n",
    "    \"result_ht\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ee98c-d853-440f-933b-8ef552c7cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "premiership_data = pd.concat(\n",
    "    [\n",
    "        premiership_data[technical_fields].reset_index(drop=True),\n",
    "        premiership_data[X_fields].reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f5157-5a17-49d4-9cdf-510c22904616",
   "metadata": {},
   "source": [
    "Now, we want to make sure that we will be using only the data that has ALL the features that we want to utilize. The features we are oriented at are aggregations and there is no value for them if a team plays their first home or away match during given season. So we will discard all the matches where this data is unavailable. In most cases, those will two first matches during the season (one home and one away). On rare occasions, it may happen that more matches will be discarded, since it is theoretically possible that the first two (or more) games of a given team were home- or away-only matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21813d1d-dd19-42e9-b79a-ff779d93cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "premiership_data = premiership_data.dropna(how=\"any\", subset=X_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e512056-8ccb-40f8-bc32-9d65caf625a8",
   "metadata": {},
   "source": [
    "To check that, we can calculate the number of matches played by a team during the season. Premiership consists of 38 game series (also called matchweeks) so, if no hiccups were experienced during the season, a team should occur 36 times in our dataset (38 - first home game - first away game)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb578037-f284-4b6d-8228-9b1afe1e2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_games = pd.concat(\n",
    "    [\n",
    "        premiership_data.groupby([\"season\", \"home_team\"])[\"result_full\"]\n",
    "        .count()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"home_team\": \"team\"}),\n",
    "        premiership_data.groupby([\"season\", \"away_team\"])[\"result_full\"]\n",
    "        .count()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"away_team\": \"team\"}),\n",
    "    ],\n",
    "    axis=0,\n",
    ").rename(columns={\"result_full\": \"games_played\"})\n",
    "num_games = num_games.groupby([\"season\", \"team\"])[\"games_played\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e607294-d953-4b10-a3a8-90d0db97e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = num_games.groupby(\"season\").value_counts().rename(\"count\").reset_index()\n",
    "\n",
    "(\n",
    "    pln.ggplot(data=plot_data, mapping=pln.aes(x=\"games_played\", y=\"count\"))\n",
    "    + pln.geom_bar(stat=\"identity\")\n",
    "    + pln.facet_wrap(\"~season\")\n",
    "    + pln.labs(\n",
    "        x=\"Games played (in the dataset)\",\n",
    "        y=\"\",\n",
    "        title=\"Number of games in the dataset per season played by given team\",\n",
    "    )\n",
    "    + pln.theme_bw()\n",
    "    + pln.theme(figure_size=(12, 10))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4765a146-4b70-4b43-99da-7916fda2d423",
   "metadata": {},
   "source": [
    "We see that in majority of cases, the teams in the dataset indeed played 36 games (so all that we could expect, given that two games of each team needed to be discarded due to lack of data). But at times it happens that there are less than 36 games in the dataset. For instance, in season 16/17, Chelsea and Leicester City have only 35 records. Leicester City played an away fixture vs. Liverppol in the 4th series, but Liverpool played only away games up to this point, so there have no record of home performance up to this point. Chelsea faced Burnley at home in the 3rd series, but Burnley played only away games up to this moment. Hence no away indicators for them.\n",
    "\n",
    "The interesting thing is with season 20/21. There are (comparably) very few games played by all the teams. It's because the data for this season ends in March, whereas the season's last matchweek occurred on the 23rd of May '21, so we see why the data is missing. This, however, shouldn't jeopardize the analysis, so we will not remove this incomplete season.\n",
    "\n",
    "TODO: Scrap the rest of the 20/21 season and potentially even 21/22."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb769ea-a6a1-488b-913c-e7e9b8f19db6",
   "metadata": {},
   "source": [
    "Having removed the rows that are not useful in the analyses, we may proceed with the creation of our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787b447-bce1-4685-8fea-269e2ea54ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "premiership_data = pd.concat(\n",
    "    [\n",
    "        premiership_data,\n",
    "        premiership_data[\"result_full\"]\n",
    "        .str.split(\"-\")\n",
    "        .apply(\n",
    "            lambda x: pd.Series(\n",
    "                {\n",
    "                    \"goals_H\": int(x[0]),  # number of goals scored by home team\n",
    "                    \"goals_A\": int(x[1]),  # number of goals scored by away team\n",
    "                    \"win_H\": int(x[0]) > int(x[1]),  # check if home team won\n",
    "                    \"win_A\": int(x[0]) < int(x[1]),  # check if away team won\n",
    "                }\n",
    "            )\n",
    "        ),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053ea6d-db01-4687-9c27-7e6843da2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "premiership_data[\"target_H\"] = np.logical_and(\n",
    "    premiership_data[\"goals_H\"] >= 2, premiership_data[\"win_H\"]\n",
    ")\n",
    "premiership_data[\"target_A\"] = np.logical_and(\n",
    "    premiership_data[\"goals_A\"] >= 2, premiership_data[\"win_A\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70311843-0a8b-4f3a-82f1-eef26530f94c",
   "metadata": {},
   "source": [
    "We have now two columns: `target_H` and `target_A` that store binary information whether home or away team meets the requirement of winning a game and scoring at least two goals (both of the conditions need to be met). What we should do now, is \"flatten\" the dataset so that we have one column - `target` that will contain both of those. We will repeat all the other fields and stack the dataset with itself. Each match will have then 2 rows - one for home and one for away team. Algorithm will see hence the same data twice during the learning process, but once it will be associated with the home team `target` and once with away team result. It will happen that for the same game both values will be 0s, but it is expected in such situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac443b-a328-470a-8079-a5553495f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.concat(\n",
    "                [\n",
    "                    premiership_data[technical_fields],\n",
    "                    premiership_data[X_fields],\n",
    "                    premiership_data[\"target_H\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ).rename(columns={\"target_H\": \"target\"}),\n",
    "            pd.concat(\n",
    "                [\n",
    "                    premiership_data[technical_fields],\n",
    "                    premiership_data[X_fields],\n",
    "                    premiership_data[\"target_A\"],\n",
    "                ],\n",
    "                axis=1,\n",
    "            ).rename(columns={\"target_A\": \"target\"}),\n",
    "        ]\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    "    .astype({\"target\": int})\n",
    ")  # convert target to integer (0 vs 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c06b9a4-ab95-4651-b66e-d0f7647ddba5",
   "metadata": {},
   "source": [
    "### Split the data into training and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2746d0b-054f-4ada-adc4-9d6b8b95fe39",
   "metadata": {},
   "source": [
    "We want to have a portion of the dataset left as validation dataset - to make final estimation of the performance quality of the algorithms we will develop. \n",
    "There are two splits we could apply:\n",
    "- Stratification within season. Under this approach, we would sample a set of games from each season and leave them as the validation set. That would make sense, since during one season the teams participating in the league are constant, so our models would probably be more capable of making viable predictions.\n",
    "- Stratification by season. In this setting, we will leave the freshest season (20/21) as the validation set. Training the model under previous assumption would be OK for discovery purposes - i.e. what are the indicators that a team will win. But this is kind of an exploratory analysis rather than forecasting. And we could argue that the latter is of more importance, since, for instance, we could use that to earn money, for example making bets (although it is morally-thin reason...).\n",
    "\n",
    "That is why we opt for the second option and we will be using the data up to the season 20/21 as the training set and 20/21 games as the validation set. We could potentially extend the validation data set to seasons 19/20 and 20/21, but we will limit ourselves only to the last season to make the validation set coherent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e7680-da59-4ab5-b184-96f5e7406702",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[\"train_val\"] = np.where(\n",
    "    training_data[\"season\"] == \"20/21\", \"val\", \"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6180f-9aa1-4045-99c8-8bdf1f7beca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Validation set amounts to {(training_data['train_val']=='val').sum() / training_data.shape[0]:.2%} of the whole data set.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1539762-e72e-4e95-acb5-a17fc57826e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data.loc[training_data[\"train_val\"] == \"train\"][X_fields]\n",
    "y_train = training_data.loc[training_data[\"train_val\"] == \"train\"][\"target\"]\n",
    "\n",
    "X_val = training_data.loc[training_data[\"train_val\"] == \"val\"][X_fields]\n",
    "y_val = training_data.loc[training_data[\"train_val\"] == \"val\"][\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf00c0-0fac-46a3-832b-9c2e080399c3",
   "metadata": {},
   "source": [
    "## A bit of EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eefa53-077c-4490-9335-cc6fd7120b9e",
   "metadata": {},
   "source": [
    "First, let's see if our datasets are balanced (or how much they are imbalanced, it's hard to expect that wins with two goals scored will as frequent as any other results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca075bd-82e5-464e-ac08-353f304c8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset, label in zip([y_train, y_val], [\"training\", \"validation\"]):\n",
    "    g = (\n",
    "        pln.ggplot(\n",
    "            data=subset.astype(\"category\").reset_index(), mapping=pln.aes(x=\"target\")\n",
    "        )\n",
    "        + pln.geom_bar(stat=\"count\", fill=\"#d1d1e0\", color=\"black\")\n",
    "        + pln.geom_text(\n",
    "            pln.aes(label=pln.after_stat(\"count\")), stat=\"count\", nudge_y=1, va=\"bottom\"\n",
    "        )\n",
    "        + pln.labs(\n",
    "            x=\"Target\",\n",
    "            y=\"\",\n",
    "            title=f\"Counts of the TARGET variable for the {label} dataset\",\n",
    "        )\n",
    "        + pln.theme_bw()\n",
    "    )\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edef0d-17f7-4355-9979-91e592eb02ad",
   "metadata": {},
   "source": [
    "Surprisingly enough, the imbalance level is not very serious. In the training set, around 30% of the games resulted in the win of one of the teams and that team scored at least 2 goals. In the validation set, this ratio is closer to 25%, but still - we are in the same ballpark - the differences between training and validation datasets are negligible. \n",
    "\n",
    "Yet another good news is that we do not have to resort to any special procedure of \"fixing\" extremely imbalanced dataset. Ratio of 1:3 is acceptable and will entail only the change in the metrics - we cannot use metrics that work well for balanced datasets (accuracy). Therefore we will be measuring performance with either F1 score or ROC AUC that are imbalance-resistant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df1e523-ae01-4c60-a1d7-3566ca89746a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c068b0a-f7df-4704-8364-d65de878bd74",
   "metadata": {},
   "source": [
    "Having the dataset prepared, we can draw some plots to see what features contribute towards the target (winning, but scoring two goals at the minimum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec2d27-1416-4e98-8dc1-d81f0f03df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.concat([X_train, y_train.astype(\"category\")], axis=1).melt(\n",
    "    id_vars=\"target\"\n",
    ")\n",
    "(\n",
    "    pln.ggplot(pln.aes(x=\"target\", y=\"value\"), plot_data)\n",
    "    + pln.geom_boxplot(fill=\"#d1d1e0\", color=\"black\")\n",
    "    + pln.facet_wrap(\"~variable\", scales=\"free_y\")\n",
    "    + pln.labs(\n",
    "        x=\"Target\",\n",
    "        y=\"Value\",\n",
    "        title=\"Boxplots for variables in the training set \\n demonstrating differences between teams meeting the target and not\",\n",
    "    )\n",
    "    + pln.theme_bw()\n",
    "    + pln.theme(figure_size=(25, 18), subplots_adjust={\"wspace\": 0.25})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446d9c1-986a-4d14-9d76-a0f0d72e657a",
   "metadata": {},
   "source": [
    "Boxplots are not as informative as we would expect them to be. Probably because classes 0 and 1 share a lot of common values through tied games or games where one team won, but scoring only one goal. We need to then use more statistical methods to approach the problem - eyeballing is not enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908451ef-338f-405b-83c0-27a8d0e3168b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bccea00-2536-4f43-bff6-946530b4f66f",
   "metadata": {},
   "source": [
    "We will run a series of statistical tests to see whether there are statistically significant differences for any of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66703258-3631-46e4-85ab-17ad4a837e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vals = []\n",
    "\n",
    "for field in X_fields:\n",
    "    _, p_val = scipy.stats.ttest_ind(\n",
    "        X_train[field].loc[y_train == 0].values, X_train[field].loc[y_train == 1].values\n",
    "    )\n",
    "    p_vals.append(p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17667a-feb6-46eb-b957-ed12dbb2e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run correction for multiple testing\n",
    "is_significant, _, _, _ = statsmodels.stats.multitest.multipletests(\n",
    "    p_vals, method=\"bonferroni\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeddd89-80c4-43eb-82e8-45aaa89310a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b870e-2158-4eed-b3cd-46b347b04b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "md(\n",
    "    \"\"\"It appears, that there exists statistical difference for {} variables (after correction for multiple testing). \n",
    "We will plot density estimation for each of those.\"\"\".format(\n",
    "        sum(is_significant)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135eca5b-b2ce-4e2d-9f0c-e7fff1639949",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.concat(\n",
    "    [X_train[np.array(X_fields)[is_significant]], y_train.astype(\"category\")], axis=1\n",
    ").melt(id_vars=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed9f824-1f5d-46ef-8169-95ea398ef887",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pln.ggplot(pln.aes(x=\"value\"), plot_data)\n",
    "    + pln.geom_density(pln.aes(fill=\"target\", color=\"target\"), alpha=0.2)\n",
    "    + pln.facet_wrap(\"~variable\", scales=\"free\")\n",
    "    + pln.labs(\n",
    "        x=\"Density estimation\",\n",
    "        y=\"\",\n",
    "        title=\"Density estimation per target for statistically significant variables\",\n",
    "    )\n",
    "    + pln.theme_bw()\n",
    "    + pln.theme(figure_size=(20, 18), subplots_adjust={\"wspace\": 0.25, \"hspace\": 0.25})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcf7722-d79a-465c-ae6f-9df0ea18f55d",
   "metadata": {},
   "source": [
    "Oddly enough, all the significant variables are related to the performance during **home games**. The shapes of the density estimators are quite similar, but for a number of cases non-target teams (so losing, tying, or winning, but scoring one goal) have greater density for lower-than-mean values for variables like `shots_on_target_avg_home`, `performance_acum_home` or `passes_avg_H`. It indicates that, on average, teams not meeting the target do have performance below average in important aspects like shots on target or number of passes, which correlates with the mental image of a \"worse\" team (technically worse - the team may still have won!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b81ddb3-d9bf-4be9-b347-b76bce9732f1",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c70e2-9231-4118-b22b-d6d1d97c8b67",
   "metadata": {},
   "source": [
    "We will build three models and assess their performance:\n",
    "- **logistic regression** - A simple and quick to train and optimize model that will serve as a benchmark.\n",
    "- **random forest** - Bagging model that is known to perform decently in multiple scenarios.\n",
    "- **gradient boosting model** - We have enough data to train a boosting model - one of the most reliable models in terms of performance.\n",
    "\n",
    "All of those models will have hyperparameters tuned (but not very deeply, to save time). We will be assessing their initial performance on 20 folds from repeated k-fold CV procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3009f30d-c38b-436e-bd37-2b581bfe0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv = RepeatedKFold(\n",
    "    n_splits=10, n_repeats=2\n",
    ")  # we will be evaluating the model on 20 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70b5f3-64a6-4d5a-84e2-1921332e7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models\n",
    "log_reg_model = Pipeline(\n",
    "    (\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\n",
    "            \"model\",\n",
    "            LogisticRegressionCV(\n",
    "                cv=5, max_iter=500, n_jobs=2, scoring=\"roc_auc\", refit=False\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "# shallow grid search for brevity\n",
    "rf_model = GridSearchCV(\n",
    "    RandomForestClassifier(n_estimators=150),\n",
    "    param_grid={\"max_depth\": [3, 6, 9, 12]},\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5,\n",
    "    refit=False,\n",
    "    n_jobs=2,\n",
    ")\n",
    "# bayesian optimization of hyperparameters - otherwise LightGBM is kind of meh\n",
    "lgbm_model = BayesSearchCV(\n",
    "    lightgbm.LGBMClassifier(n_estimators=150),\n",
    "    search_spaces={\n",
    "        \"max_depth\": Integer(5, 15),\n",
    "        \"learning_rate\": Real(1e-3, 0.5, prior=\"log-uniform\"),\n",
    "        \"reg_alpha\": Real(1e-3, 1, prior=\"log-uniform\"),\n",
    "        \"reg_lambda\": Real(1e-3, 1, prior=\"log-uniform\"),\n",
    "    },\n",
    "    n_iter=25,\n",
    "    cv=5,\n",
    "    n_jobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e832b92-0b6f-4639-8b8c-95274590785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_results = cross_validate(\n",
    "    log_reg_model, X_train, y_train, scoring=\"roc_auc\", cv=rcv, n_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556c3f4-b114-4052-ae94-47601010ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_results[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58695d-3ace-4555-9ceb-323f81e3be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = cross_validate(\n",
    "    log_reg_model, X_train, y_train, scoring=\"roc_auc\", cv=rcv, n_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf6d23-e5a2-44c5-8970-e574401e7e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ca07a-e125-4e6e-bd68-2eb3cb5b90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# be carefeul - it takes quite a long time to process!\n",
    "lgbm_results = cross_validate(\n",
    "    lgbm_model, X_train, y_train, scoring=\"roc_auc\", cv=rcv, n_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a348f-af1d-4882-9fd5-50dd8ff4dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_results[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967cca7-89d1-4769-bc17-87c2e391fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame({\"model\": \"LR\", \"cv_scores\": log_reg_results[\"test_score\"]}),\n",
    "        pd.DataFrame({\"model\": \"RF\", \"cv_scores\": rf_results[\"test_score\"]}),\n",
    "        pd.DataFrame({\"model\": \"LGBM\", \"cv_scores\": lgbm_results[\"test_score\"]}),\n",
    "    ]\n",
    ")\n",
    "\n",
    "(\n",
    "    pln.ggplot(data=plot_data, mapping=pln.aes(x=\"model\", y=\"cv_scores\"))\n",
    "    + pln.geom_boxplot()\n",
    "    + pln.geom_hline(pln.aes(yintercept=0.5), size=2, linetype=\"dashed\")\n",
    "    + pln.labs(x=\"Model\", y=\"ROC AUC\", title=\"ROC AUC scores in 2x-repeated 10-fold CV\")\n",
    "    + pln.theme_bw()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6beec-7653-4526-b922-14c4d6ec27eb",
   "metadata": {},
   "source": [
    "As can be seen from the plot above, the performance of the model in thorough cross-validation is very poor, almost indistinguishable from a random model (with ROC AUC of 0.5). It may suggest that the variables that we use do not have sufficient explanatory power to deal with the problem at hand. But it's to early to assess, since the main culprit may be faulty problem formulation. Under the assumed approach, where each match makes up two observations (one for home team and one for away team), we may inject mixed-up information at the training stage. Our explanatory variables have, broadly speaking, 2 subgroups: a set of variables pertaining to the home team and the same variables for away team. But the target variable is not linked to them, since at times the home team has a value of 1 there and sometimes - the away team. The situation is exacerbated especially when there are two 0s for a given match.\n",
    "\n",
    "What is more, the problem is ill-formulated also for another reason - two teams playing in one fixture are assessed independently, so it would be theoretically possible for both of them to receive a 1 as an output, which is clearly wrong, since two teams cannot win the same game... Should a model perform decently, that wouldn't be a problem, but given the weak performance in CV, we could be expecting all kind of undesired behaviors.\n",
    "\n",
    "On a side note, we will not use the validation set that we set aside, as CV performance doesn't promise anything positive from such type of an experiment.\n",
    "\n",
    "Therefore this approach may not be optimal and we need to reformulate the approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f524fa7b-ac73-4e19-8e65-05fff54a065b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3b85f3-643e-49de-9602-96bfff20e006",
   "metadata": {},
   "source": [
    "## Three-class approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fa2833-adbe-4c9b-b272-ceade6ded9a4",
   "metadata": {},
   "source": [
    "As an alternative to the (failing) approach above, we may propose a three-class approach, where a match can have three outcomes:\n",
    "- home team wins scoring at least 2 goals;\n",
    "- away team wins scoring at least 2 goals;\n",
    "- no team wins scoring at least 2 goals (but still one of them may win 1-0).\n",
    "\n",
    "This formulation can alleviate both of the issues we spotted above - there will be one observation per game, so only one outcome for the game will be possible (no contradictions) and the model will have a chance to tie home-team variables to the success (or not) of the home team, similarly with the away team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e9a1d-38b7-47b3-a292-65dc7537a02f",
   "metadata": {},
   "source": [
    "### Prepare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5d0d6-375a-471c-9cf6-d06abd9a76dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new variable that can take on three values - 1 if the home team meets requirements, 2 if the away team meets them and 0 otherwise\n",
    "three_class_data = premiership_data.assign(\n",
    "    three_class_target=lambda x: np.where(\n",
    "        np.logical_and(x[\"goals_H\"] > x[\"goals_A\"], x[\"goals_H\"] >= 2),\n",
    "        1,\n",
    "        np.where(np.logical_and(x[\"goals_A\"] > x[\"goals_H\"], x[\"goals_A\"] >= 2), 2, 0),\n",
    "    )\n",
    ").drop(columns=[\"goals_H\", \"goals_A\", \"win_H\", \"win_A\", \"target_H\", \"target_A\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306a28e-3af1-4cea-a69c-8dbb42b8793c",
   "metadata": {},
   "source": [
    "Unlike in previous case, where we were using CV for initial validation of models, we will need now two validation sets: one to measure performance of the neural network during the training and one to make final conclusions. We will set aside the last two seasons for that reason. 19/20 for the network to indicate its performance and 20/21 as the final evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b752911-0aca-424e-8d90-acea3e416d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_class_data[\"train_test_val\"] = np.where(\n",
    "    three_class_data[\"season\"] == \"19/20\",\n",
    "    \"test\",\n",
    "    np.where(three_class_data[\"season\"] == \"20/21\", \"val\", \"train\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977e8a5-7469-4c94-a6e2-ac6f3caf8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_class_data[\"train_test_val\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9303d1-b92b-456b-befd-a45f9b5ffbe6",
   "metadata": {},
   "source": [
    "The training set will still be big enough to train the network viably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a9a9b-f01b-41cd-828c-6d741527e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = three_class_data[X_fields].loc[three_class_data[\"train_test_val\"] == \"train\"]\n",
    "X_test = three_class_data[X_fields].loc[three_class_data[\"train_test_val\"] == \"test\"]\n",
    "X_val = three_class_data[X_fields].loc[three_class_data[\"train_test_val\"] == \"val\"]\n",
    "\n",
    "y_train = three_class_data[\"three_class_target\"].loc[\n",
    "    three_class_data[\"train_test_val\"] == \"train\"\n",
    "]\n",
    "binarizer = LabelBinarizer()\n",
    "y_train = binarizer.fit_transform(y_train)\n",
    "y_test = binarizer.transform(\n",
    "    three_class_data[\"three_class_target\"].loc[\n",
    "        three_class_data[\"train_test_val\"] == \"test\"\n",
    "    ]\n",
    ")\n",
    "y_val = binarizer.transform(\n",
    "    three_class_data[\"three_class_target\"].loc[\n",
    "        three_class_data[\"train_test_val\"] == \"val\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd05fa-dd79-43f3-8317-9e6b529bf794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we build a small feed-forward network with three outputs to address our\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(128, input_shape=(len(X_fields),), activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(32, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "# train the model using SGD\n",
    "adam = keras.optimizers.Adam(0.0001)\n",
    "# categorical accuracy is not the best metric, but keras doesn't offer better ones off-the-shelf\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"categorical_accuracy\"]\n",
    ")\n",
    "# we declare early stopping criterion, but eventually - we do not use it\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", patience=4, min_delta=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a1241-315c-4ace-b4d8-9328822fe8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=150,\n",
    "    batch_size=256,\n",
    "    callbacks=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d69e896-5931-462e-a963-01e81c185d4d",
   "metadata": {},
   "source": [
    "Let's see the model performance in the form of confusion matrix (on the test set, the same one that was used to control network's quality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e081b3-94a9-4e82-b6b6-05dc4fdc1ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17357410-0eec-459a-88ef-83ca2e10b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(\n",
    "    three_class_data[\"three_class_target\"]\n",
    "    .loc[three_class_data[\"train_test_val\"] == \"test\"]\n",
    "    .values,\n",
    "    y_test_preds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd54ea1f-1fd7-41d1-aebb-c478a9c04828",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d8adc-4bff-4b3f-b7e1-1ee7f26e90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_class_data[\"three_class_target\"].loc[\n",
    "    three_class_data[\"train_test_val\"] == \"train\"\n",
    "].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06981b38-f734-4d1b-8372-f96c79646e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        three_class_data[\"three_class_target\"]\n",
    "        .loc[three_class_data[\"train_test_val\"] == \"test\"]\n",
    "        .values,\n",
    "        y_test_preds,\n",
    "        target_names=[\n",
    "            \"Nothing interesting\",\n",
    "            \"Home team triggered\",\n",
    "            \"Away team trigerred\",\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18edaf3-f2b7-470e-94df-75b9c679a012",
   "metadata": {},
   "source": [
    "From the confusion matrix and classification report we can conclude that the network learned _something_, but it is not enough to establish a trustworthy model. The model is considerably skewed towards class 0 (none team met the requirements) and makes many mistakes trying to assign classifies matches to this group. On the other hand, class 2 (away team wins scoring 2 goals) is considerably underestimated. We see recall of only 0.1, so only one in ten matches ending with this outcome is actually recognized. But in general, there are very few matches classified as 2 by the model. This shouldn't be the case, since in the train set this is the least frequent class, but not to extend when it should be that heavily disregarded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e5e2e-8390-42a0-9a0d-359bcdd31588",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bd2ee9-4473-4869-a7dd-da5dd8377286",
   "metadata": {},
   "source": [
    "Overall, it turned out that the task at hand is not a low-hanging fruit and seems not to be a task that is easy to model. There are some ways which one could take from now on:\n",
    "- Train another model for the three-class problem (LightGBM, which tends to excel for tabular data). That could help in assessment of the poor performance of the network model as it could either be misspecification of the model or the data problem on its own.\n",
    "- Carry out some feature engineering. One idea here could be to calculate differences in corresponding features between home and away teams. That would simplify the feature space. \n",
    "- Accept a little bit romantic approach that football at its core is unpredictable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
